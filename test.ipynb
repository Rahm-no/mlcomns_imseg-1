{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import hashlib\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXCLUDED_CASES = []#[23, 68, 125, 133, 15, 37]\n",
    "MAX_ID = 210\n",
    "MEAN_VAL = 101.0\n",
    "STDDEV_VAL = 76.9\n",
    "MIN_CLIP_VAL = -79.0\n",
    "MAX_CLIP_VAL = 304.0\n",
    "TARGET_SPACING = [1.6, 1.2, 1.2]\n",
    "TARGET_SHAPE = [128, 128, 128]\n",
    "class Stats:\n",
    "    def __init__(self):\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        self.d = []\n",
    "        self.h = []\n",
    "        self.w = []\n",
    "\n",
    "    def append(self, mean, std, d, h, w):\n",
    "        self.mean.append(mean)\n",
    "        self.std.append(std)\n",
    "        self.d.append(d)\n",
    "        self.h.append(h)\n",
    "        self.w.append(w)\n",
    "\n",
    "    def get_string(self):\n",
    "        self.mean = np.median(np.array(self.mean))\n",
    "        self.std = np.median(np.array(self.std))\n",
    "        self.d = np.median(np.array(self.d))\n",
    "        self.h = np.median(np.array(self.h))\n",
    "        self.w = np.median(np.array(self.w))\n",
    "        return f\"Mean value: {self.mean}, std: {self.std}, d: {self.d}, h: {self.h}, w: {self.w}\"\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, args):\n",
    "        self.mean = MEAN_VAL\n",
    "        self.std = STDDEV_VAL\n",
    "        self.min_val = MIN_CLIP_VAL\n",
    "        self.max_val = MAX_CLIP_VAL\n",
    "        self.results_dir = args.results_dir\n",
    "        self.data_dir = args.data_dir\n",
    "        self.target_spacing = TARGET_SPACING\n",
    "        self.stats = Stats()\n",
    "\n",
    "    def preprocess_dataset(self):\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "        print(f\"Preprocessing {self.data_dir}\")\n",
    "        for case in sorted([f for f in os.listdir(self.data_dir) if \"case\" in f]):\n",
    "            case_id = int(case.split(\"_\")[1])\n",
    "            if case_id in EXCLUDED_CASES or case_id >= MAX_ID:\n",
    "                print(\"Case {}. Skipped.\".format(case_id))\n",
    "                continue\n",
    "            image, label, image_spacings = self.load_pair(case)\n",
    "            image, label = self.preprocess_case(image, label, image_spacings)\n",
    "            image, label = self.pad_to_min_shape(image, label)\n",
    "            self.save(image, label, case)\n",
    "        print(self.stats.get_string())\n",
    "\n",
    "    def preprocess_case(self, image, label, image_spacings):\n",
    "        image, label = self.resample3d(image, label, image_spacings)\n",
    "        image = self.normalize_intensity(image.copy())\n",
    "        return image, label\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_to_min_shape(image, label):\n",
    "        current_shape = image.shape[1:]\n",
    "        bounds = [max(0, TARGET_SHAPE[i] - current_shape[i]) for i in range(3)]\n",
    "        paddings = [(0, 0)]\n",
    "        paddings.extend([(bounds[i] // 2, bounds[i] - bounds[i] // 2) for i in range(3)])\n",
    "        return np.pad(image, paddings, mode=\"edge\"), np.pad(label, paddings, mode=\"edge\")\n",
    "\n",
    "    def load_pair(self, case: str):\n",
    "        image = nibabel.load(os.path.join(self.data_dir, case, \"imaging.nii.gz\"))\n",
    "        label = nibabel.load(os.path.join(self.data_dir, case, \"segmentation.nii.gz\"))\n",
    "        image_spacings = image.header[\"pixdim\"][1:4].tolist()\n",
    "        image, label = image.get_fdata().astype(np.float32), label.get_fdata().astype(np.uint8)\n",
    "        image, label = np.expand_dims(image, 0), np.expand_dims(label, 0)\n",
    "        return image, label, image_spacings\n",
    "\n",
    "    def resample3d(self, image, label, image_spacings):\n",
    "        if image_spacings != self.target_spacing:\n",
    "            spc_arr = np.array(image_spacings)\n",
    "            targ_arr = np.array(self.target_spacing)\n",
    "            shp_arr = np.array(image.shape[1:])\n",
    "            new_shape = (spc_arr / targ_arr * shp_arr).astype(int).tolist()\n",
    "\n",
    "            image = interpolate(torch.from_numpy(np.expand_dims(image, 0)),\n",
    "                                size=new_shape, mode='trilinear', align_corners=True)\n",
    "            label = interpolate(torch.from_numpy(np.expand_dims(label, 0)), size=new_shape, mode='nearest')\n",
    "            image = np.squeeze(image.numpy(), 0)\n",
    "            label = np.squeeze(label.numpy(), 0)\n",
    "        return image, label\n",
    "\n",
    "    def normalize_intensity(self, image: np.array):\n",
    "        image = np.clip(image, self.min_val, self.max_val)\n",
    "        image = (image - self.mean) / self.std\n",
    "        return image\n",
    "\n",
    "    def save(self, image, label, case: str):\n",
    "        image = image.astype(np.float32)\n",
    "        label = label.astype(np.uint8)\n",
    "        mean, std = np.round(np.mean(image, (1, 2, 3)), 2), np.round(np.std(image, (1, 2, 3)), 2)\n",
    "        print(f\"Saving {case} shape {image.shape} mean {mean} std {std}\")\n",
    "        self.stats.append(mean, std, image.shape[1], image.shape[2], image.shape[3])\n",
    "        np.save(os.path.join(self.results_dir, f\"{case}_x.npy\"), image, allow_pickle=False)\n",
    "        np.save(os.path.join(self.results_dir, f\"{case}_y.npy\"), label, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_slices(slices):\n",
    "    fig, axes = plt.subplots(1, len(slices))\n",
    "    for i, slice in enumerate(slices):\n",
    "        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "    plt.suptitle(\"Center slices for EPI image\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = nibabel.load(os.path.join(\"/data/kits19/data/case_00001\", \"imaging.nii.gz\"))\n",
    "image = image.get_fdata()\n",
    "shapes = image.shape\n",
    "shape_0 = shapes[0]//2\n",
    "shape_1 = shapes[1]//2\n",
    "shape_2 = shapes[2]//2\n",
    "slices = [image[shape_0, :, :], image[:, shape_1, :], image[:, :, shape_2]]\n",
    "show_slices(slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
